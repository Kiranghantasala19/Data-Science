{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb766957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Imports\n",
    "# -------------------------------\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_classic.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ecb4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. Initialize Ollama LLM\n",
    "# -------------------------------\n",
    "llm = Ollama(\n",
    "    model=\"llama3\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1d8195d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Initialize Embeddings\n",
    "# -------------------------------\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43a61910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 4. Create Vector Store\n",
    "# -------------------------------\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"my_rag\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "91910697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['450cbd54-7660-4182-94f1-991252a09be7',\n",
       " '577ba72d-c99a-4dbd-975e-0f48850687fb',\n",
       " '7e679435-0402-4d58-ab88-6e81866c2bd8']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5. Add Documents\n",
    "# -------------------------------\n",
    "docs = [\n",
    "    Document(page_content=\"Ollama runs locally.\"),\n",
    "    Document(page_content=\"Gemini requires API keys.\"),\n",
    "    Document(page_content=\"The average transaction amount is 2,500 INR.\")\n",
    "]\n",
    "\n",
    "vector_store.add_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a47df69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 6. Create Retriever\n",
    "# -------------------------------\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54eaa571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 7. Prompt Template\n",
    "# -------------------------------\n",
    "policy_prompt = \"\"\"\n",
    "You are a helpful assistant.\n",
    "Use ONLY the provided context to answer the question.\n",
    "If the answer is not in the context, say \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=policy_prompt + \"\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{question}\\n\\nAnswer:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff063a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------------------------------\n",
    "# 8. RetrievalQA Chain\n",
    "# -------------------------------\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "208acece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Summarize the average transaction amount from the stored data.', 'result': 'According to the provided context, the average transaction amount is 2,500 INR.'}\n",
      "{'query': 'What is the average transaction amount?', 'result': 'According to the provided context, the answer is:\\n\\n2,500 INR'}\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 9. Queries\n",
    "# -------------------------------\n",
    "print(qa_chain.invoke(\"Summarize the average transaction amount from the stored data.\"))\n",
    "print(qa_chain.invoke(\"What is the average transaction amount?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbf2d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
